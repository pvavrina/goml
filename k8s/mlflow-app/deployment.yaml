# k8s/mlflow-app/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mlflow
  labels:
    app: mlflow
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mlflow
  template:
    metadata:
      labels:
        app: mlflow
    spec:
      containers:
      - name: mlflow
        # Use your actual MLflow Docker image here
        image: python:3.10-slim 
        ports:
          - containerPort: 5000
        resources:
          limits:
            memory: "1Gi" # Confirmed stable memory limit
          requests:
            memory: "512Mi"
        
        # Direct execution of Gunicorn to bypass the 'mlflow server' UI bug
        command:
          - gunicorn
        args:
          # Gunicorn worker configuration
          - --bind
          - 0.0.0.0:5000
          - --worker-class
          - uvicorn.workers.UvicornWorker
          - --threads
          - "8"
          - mlflow.server:app # The MLflow Python application entry point
        
        env:
          # Database connection
          - name: MLFLOW_TRACKING_URI
            value: "postgresql://mlflow_user:password@postgres-clusterip-service:5432/mlflow_db"
          # Artifact Root (Essential for persisting models and UI assets)
          - name: MLFLOW_DEFAULT_ARTIFACT_ROOT
            value: /mlflow-artifacts
          # Allows Gunicorn to handle requests correctly when running behind a proxy (Traefik)
          - name: GUNICORN_CMD_ARGS
            value: "--forwarded-allow-ips=*"
          # Additional environment variables for MLflow API
          - name: MLFLOW_SERVER_HOST
            value: 0.0.0.0
          - name: MLFLOW_SERVER_PORT
            value: "5000"
        
        # Mount the volume for artifact storage
        volumeMounts:
          - name: mlflow-artifact-storage
            mountPath: /mlflow-artifacts
      
      # Define the volume based on the PersistentVolumeClaim (PVC)
      volumes:
        - name: mlflow-artifact-storage
          persistentVolumeClaim:
            claimName: mlflow-pvc
